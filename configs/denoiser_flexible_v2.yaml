paths:
  runs_root: soundrestorer/runs
  run_name: den_progress

callbacks:
  curriculum:
    enable: true
    snr_stages:
      - {until: 2,   snr_min: 14, snr_max: 20, use_ext_noise_p: 0.5}
      - {until: 8,   snr_min:  4, snr_max: 20, use_ext_noise_p: 0.7}
      - {until: 9999,snr_min: -3, snr_max: 20, use_ext_noise_p: 0.8}
    sisdr:
      start_db: 0.0
      end_db: 12.0
      end_epoch: 15
    mask_limit: {start: 1.25, end: 2.0, end_epoch: 12}
    mask_variant:
      - {until: 5,    variant: delta1}   # keep identity-anchored first
      - {until: 9999, variant: plain}    # switch to complex

data:
  train_manifest: soundrestorer/data/training/train.jsonl
  val_manifest:   soundrestorer/data/training/val.jsonl
  sr: 48000
  crop: 3.0
  mono: true

  batch: 8
  workers: 8
  prefetch_factor: 4
  pin_memory: true
  persistent_workers: true
  cache_gb: 2.0
  no_cache: false

  # dataset-side mixing (if supported by your dataset)
  snr_min: 0.0
  snr_max: 20.0
  use_ext_noise_p: 0.5
  min_clean_rms_db: -40.0
  max_retries: 644
  out_peak: 0.98

  p_clean: 0.10
  add_synth_noise_p: 0.7


  hard_mining:
    enable: true

model:
  # Switch here: complex_unet | complex_unet_lstm | complex_unet_auto
  name: complex_unet_auto
  args:
    base: 48

task:
  name: denoise_stft
  args:
    n_fft: 1024
    hop: 256
    mask_variant: delta1
    mask_limit: 1.25
    clamp_mask_tanh: 4.0        # NEW: typical safe value (try 3–6)
    safe_unity_fallback: true   # NEW

losses:
  items:
    - {name: mrstft,      weight: 1.0}
    - {name: l1_wave,     weight: 0.5}
    - {name: sisdr_ratio, weight: 0.30, args: {min_db: 6.0, cap: 1.0}}
    - {name: mel_l1,      weight: 0.15, args: {sr: 48000, n_mels: 64, n_fft: 1024, hop: 256}}
    - {name: highband_l1, weight: 0.10, args: {sr: 48000, cutoff_khz: 8.0, n_fft: 1024, hop: 256}}
    - {name: phase_cosine,weight: 0.02, args: {n_fft: 1024, hop: 256}}
    - {name: energy_anchor, weight: 0.010}

loss:
  train_trim_frac: 0.10
  train_loss_clip: 0.0
  val_trim_frac: 0.05


debug:
  print_pair_sisdr: true  # include SI(noisy,clean) and SI(yhat,clean) in dbg line
  print_comp: true        # print per-component train loss means per epoch
  step_interval: 0        # no per-step prints
  pbar_every: 8
  dump_skips: false       # no WAV dump on skipped batches
  print_cuda_mem: false   # lighter bars


train:
  epochs: 150
  save_every: 1
  ema: 0.995

optim:
  wd: 1.0e-4
  grad_clip: 3.0
  grad_accum: 1
  warmup_steps: 200     # from 300 (or 500 → 200)
  lr: 3.0e-4
  lr_min_factor: 0.3

runtime:
  amp: bfloat16
  channels_last: true
  cuda_graph: false
  compile: false
  compile_backend: inductor   # tries Triton if present, else falls back to aot_eager
  compile_mode: default       # default is fine; avoid "max-autotune" on your card
  cuda_prefetch: true
  guard_rescue_after: 32
  guard_rescue_skip_ratio: 0.5
  warmup_batches: 8    # try 4–8; 0 disables warmup

hard_mining:
  start_epoch: 3
  ema: 0.9
  top_frac: 0.30
  boost: 4.0
  baseline: 1.0


guard:
  enable: true            # (optional flag; you can ignore in code if you always create it)
  hard_clip: 0.0
  window: 512
  min_hist: 64
  mad_floor_abs: 0.20
  mad_floor_rel: 0.20
  rel_factor: 1.6
  mad_k: 8.0          # was 6.0
  snr_floor_db: -9.0  # was -6.0
  min_rms_db: -70.0
  max_peak: 1.2
